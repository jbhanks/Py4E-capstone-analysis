{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design the database based on the data\n",
    "* #### This notebook parses metadata associated with some of the datasets, most especially the PLUTO dataset, which contains columns that are also in many other datasets I looked at on NYCOpenData.\n",
    "* #### In some cases I had to search around to find more complete definitions than were included in the data dictionary associated with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import time\n",
    "import dill\n",
    "time.sleep(5) # This seems to be necessary to avoid an error about dill not being loaded in the next cell. Sometimes even that is not enough and this cell needs to be run again.\n",
    "from bisect import bisect_left\n",
    "from itertools import tee\n",
    "from src.models import ColCustomization\n",
    "from src.helpers import *\n",
    "from src.pdfutils import *\n",
    "from src.dbutils import *\n",
    "from geoalchemy2 import Geometry\n",
    "from sqlalchemy import String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the objects created in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment\n",
    "with open(\"environment_data/select.pkl\", \"rb\") as f:\n",
    "    env = dill.load(f)\n",
    "\n",
    "# Restore the environment\n",
    "globals().update(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'assessments' in dataset_info_dict:\n",
    "    column_types = dataset_info_dict['assessments'].col_types\n",
    "    print(column_types)\n",
    "    print(len(column_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_info in dataset_info_dict.values():\n",
    "    # if 'address' in dataset_info.col_types:\n",
    "    #     print(f\"Creating building_num and street_name columns for dataset {dataset_info.short_name}\")\n",
    "    #     dataset_info.col_types['building_num'] = 'text'\n",
    "    #     dataset_info.col_types['street_name'] = 'text'\n",
    "    # column_types = dataset_info.col_types\n",
    "    dataset_info.col_types = set_dtypes(filename=dataset_info.dataset_path, column_types = dataset_info.col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(dataset_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### The MapPLUTO dictionary contains most of the information we need to interpret various codes and categories meaningfully.\n",
    "* #### Unfortunately, it is in PDF format (as are many of the data dictionaries on NYCOpenData), which made extracting all the relevant data a real pain, and I don't expect most of these functions will be fully reusable for other PDFs I may encounter in the future. My hope is that it will still give me a head start when I need to make custom functions for future PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '/home/james/Massive/PROJECTDATA/nyc_real_estate_data/dictionaries/mapPLUTO_data_dictionary.pdf'\n",
    "filename = f\"{PROJECT_DATA}/dictionaries/mapPLUTO_data_dictionary.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Looking at the PLUTO data dictionary, it seems that most category variables are labeled as \"alpahnumeric\" even if they only contain numbers, such as zip codes.\n",
    "* There are some exceptions, police precincts and districts are numeric and listed as such. However as there a limited number of repeating variables, I wil treat them as categorical as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_by_section = map_pdf(filename, same_line_tolerance=0.3, start_page=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_markers = ['code', 'category', 'class', 'district', 'precinct', 'company', 'name', 'health_area', 'type', 'borough', 'name', 'health_area', 'health_center_district', 'overlay', 'designation_number', 'map_num']\n",
    "\n",
    "column_customizations=[]\n",
    "\n",
    "\n",
    "for section in pdf_by_section:\n",
    "    column_customizations += parse_pluto_dict_sections(section, category_markers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add tables from appendixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_customizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dicts = parse_zoning(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess dictionary keys by truncating last letter (for singular/plural matching)\n",
    "truncated_keys = {key[:-1]: value for key, value in table_dicts.items()}\n",
    "\n",
    "# Create a sorted list of `new_name` for efficient prefix search\n",
    "sorted_new_names = sorted(item.new_name for item in column_customizations)\n",
    "col_customization_dict = {item.new_name: item for item in column_customizations}\n",
    "\n",
    "# Apply updates\n",
    "for key, value in truncated_keys.items():\n",
    "    print(key)\n",
    "    matches = find_matching_keys(key, sorted_new_names)\n",
    "    print(matches)\n",
    "    for match in matches:\n",
    "        col_customization_dict[match].definitions = value  # Update definitions\n",
    "        col_customization_dict[match].is_category = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set BBL to not be a category\n",
    "col_customization_dict['borough_tax_block_and_lot'].is_category = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Appendix D:\n",
    "### Extract the last table, which isn't actually a table, just text arranged in a table-like way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "header_x_thresh = 10\n",
    "header_y_thresh = 20\n",
    "body_x_thresh = 10\n",
    "body_y_thresh = 10\n",
    "column_gap_thresh = 20  # Adjust based on observed spacing\n",
    "ncol = 3\n",
    "\n",
    "with pdfplumber.open(filename) as pdf:\n",
    "    words = pdf.pages[-1].extract_words()  # Extract words from page 0\n",
    "    merged_rows = merge_words_into_rows(words, header_x_thresh, header_y_thresh, body_x_thresh, body_y_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_table = []\n",
    "for idx,row in enumerate(merged_rows[1:]):\n",
    "    new_row = []\n",
    "    for idx2,cell in enumerate(row[0]):\n",
    "        new_row.append(merge_text_in_cell(cell))\n",
    "    last_table.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_customization_dict['land_use_category'].definitions = last_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get explanations of zoning codes.\n",
    "* I could only find this information in pdf form.\n",
    "* I discovered how hard PDFs can be to parse.\n",
    "* I had to do a lot of customization for just this specific pdf. I could have just manually cut and pasted the data from the pdf in the amount of time it took me to do that.\n",
    "* I still think it was good to do for reproducibility reasons, but in the future I will try to avoid working with datasets that have important information only in PDF format.\n",
    "* The following functions extract the tables from the pdf, detecting footnotes, and then subsitute the foonote number for the footnote text within the dataframe (so that it will end up as part of the relevant record in the databasee)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.nyc.gov/assets/bronxcb8/pdf/zoning_table_all.pdf\"\n",
    "filename = \"zoning_table_all.pdf\"  # Path to save the pdf containing the info we need\n",
    "\n",
    "downloader(\n",
    "            url=url,\n",
    "            download_path=f\"{PROJECT_DATA}/dictionaries/\",\n",
    "            outfile_name=filename,\n",
    "            bigfile=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the above functions to extract the data from the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_and_footnotes = parse_zoning_details(f\"{PROJECT_DATA}/dictionaries/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_and_footnotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tablename in tables_and_footnotes.keys():\n",
    "    print(tablename)\n",
    "    df = tables_and_footnotes[tablename]['df']\n",
    "    df.name = df.index.name\n",
    "    # with engine.connect() as conn:\n",
    "    for series_name, series in df.items():\n",
    "        tdf = pd.DataFrame(series)\n",
    "        tdf.reset_index(inplace=True)\n",
    "        jstring = pd.DataFrame(tdf).to_json()\n",
    "        col_customization_dict['zoning_district_1'].definitions.append([series_name, jstring])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The PDF parsed above still has some definitions that are in text outside the tables. From `zoning_table_all.pdf`:\n",
    "\n",
    ">C1-1 through C1-5 and C2-1 through C2-5 are commercial districts which are mapped as overlays within residential districts. When a commercial overlay is mapped within an R1 through R5 district, except an R5D district, the commercial FAR is 1.0; within an R5D district or an R6 through R10 district, the commercial FAR is 2.0. The residential FAR for a commercial overlay district is determined by the residential district regulations.\n",
    "\n",
    "* I need to manually create the object to hold this information and put it in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_zones = {}\n",
    "info = \"Commercial districts which are mapped as overlays within residential districts. When a commercial overlay is mapped within an R1 through R5 district, except an R5D district, the commercial FAR is 1.0; within an R5D district or an R6 through R10 district, the commercial FAR is 2.0. The residential FAR for a commercial overlay district is determined by the residential district regulations.\"\n",
    "for i in range(1,6):\n",
    "    more_zones[f'C1-{i}'] = info\n",
    "    more_zones[f'C2-{i}'] = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in more_zones.keys():\n",
    "    col_customization_dict['commercial_overlay_1'].definitions.append([key, more_zones[key]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a few more code meanings \n",
    "* From [NYC Department of Tax and Finance Data Dictionary](https://www.nyc.gov/assets/finance/downloads/tar/tarfieldcodes.pdf):\n",
    "    * LandUse\n",
    "    * OwnerType\n",
    "    * Easment code\n",
    "* Additional information about commercial zoning that I have not included can be [found here](https://www.nyc.gov/assets/planning/download/pdf/zoning/districts-tools/commercial_zoning_data_tables.pdf).\n",
    "* Additional information about residential zoning that I have not included can be [found here](https://www.nyc.gov/assets/planning/download/pdf/zoning/districts-tools/residence_zoning_data_tables.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the meanings of the building classification codes from the City of New York website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request #, urllib.parse, urllib.error\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "webpage = \"https://www.nyc.gov/assets/finance/jump/hlpbldgcode.html\"\n",
    "\n",
    "trs = get_table_rows(webpage)\n",
    "\n",
    "class_codes = []\n",
    "d = None\n",
    "for tr in trs:    \n",
    "    # Check if 'a' with 'name' exists\n",
    "    a = tr.find('a', attrs={'name': True})\n",
    "    if a:\n",
    "        if d:\n",
    "            class_codes.append(d)\n",
    "        supercategory = tr.find_all('th')[1].text.capitalize()\n",
    "        d = {\"supercategory\": supercategory}\n",
    "    \n",
    "    # Check if 'td' exists and update 'd'\n",
    "    cells = tr.find_all('td')\n",
    "    if cells:\n",
    "        d = {}\n",
    "        code, name = cells[:2]\n",
    "        d['code'] = code.text.strip()\n",
    "        d['name'] = name.text.capitalize().strip()\n",
    "        class_codes.append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in class_codes:\n",
    "    col_customization_dict['building_class'].definitions.append([row['code'], row['name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info_dict['mapPLUTO'].col_customizations = col_customization_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,info in dataset_info_dict.items():\n",
    "    # print(info.col_customizations)\n",
    "    if info.col_types.items():\n",
    "        if not info.col_customizations:\n",
    "            info.col_customizations = {short_name : ColCustomization(short_name=short_name, dtype=dtype) for short_name,dtype in info.col_types.items()}\n",
    "        for key,val in info.cardinality_ratios.items():\n",
    "            if val > 20 and info.col_customizations is not None and info.col_types[key] == String:\n",
    "                info.col_customizations[key].is_category = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(dataset_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info_dict['mapPLUTO'].col_customizations['e-designation_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"environment_data/table_dicts.pkl\", \"wb\") as f:\n",
    "    dill.dump(\n",
    "        {\n",
    "            \"dataset_info_dict\": dataset_info_dict,\n",
    "            \"PROJECT_PATH\": PROJECT_PATH,\n",
    "            \"PROJECT_DATA\": PROJECT_DATA,\n",
    "            \"SQLITE_PATH\": SQLITE_PATH,\n",
    "            \"DATADIR\": DATADIR,\n",
    "            \"PROJECT_NAME\": PROJECT_NAME,\n",
    "            \"PROJECT_DATA\": PROJECT_DATA,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyc_property",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
